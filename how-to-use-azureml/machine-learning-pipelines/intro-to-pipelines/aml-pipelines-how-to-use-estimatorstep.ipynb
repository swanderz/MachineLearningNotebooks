{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-how-to-use-estimatorstep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use EstimatorStep in AML Pipeline\n",
    "\n",
    "This notebook shows how to use the EstimatorStep with Azure Machine Learning Pipelines. Estimator is a convenient object in Azure Machine Learning that wraps run configuration information to help simplify the tasks of specifying how a script is executed.\n",
    "\n",
    "\n",
    "## Prerequisite:\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../configuration.ipynb) to:\n",
    "    * install the AML SDK\n",
    "    * create a workspace and its configuration file (`config.json`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First let's import some Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.41\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: avadevitsmlsvc\n",
      "Azure region: westus2\n",
      "Subscription id: ff2e23ae-7d7c-4cbd-99b8-116bb94dca6e\n",
      "Resource group: RG-ITSMLTeam-Dev\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config(path=\"C:\\\\Users\\\\anders.swanson\\\\Documents\\\\attrition\\\\compute\\\\aml_config\\\\config.json\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default AmlCompute\n",
    "You can create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you use default `AmlCompute` as your training compute resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster,mpi-test2,use it.\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-06-12T21:49:51.507000+00:00', 'errors': None, 'creationTime': '2019-06-12T21:49:40.574046+00:00', 'modifiedTime': '2019-06-12T21:49:56.586313+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 3, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget, DataFactoryCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "def get_or_create_compute(workspace, compute_target_name, **kwargs):\n",
    "    try:\n",
    "        compute_target = ComputeTarget(workspace=workspace, name=compute_target_name)\n",
    "        print('Found existing cluster,{},use it.'.format(compute_target_name))\n",
    "    except ComputeTargetException:\n",
    "        compute_target = ComputeTarget.create(\n",
    "            workspace,\n",
    "            compute_target_name,\n",
    "            AmlCompute.provisioning_configuration(**kwargs))\n",
    "\n",
    "        compute_target.wait_for_completion(show_output=True)\n",
    "    return compute_target\n",
    "\n",
    "cpu_cluster = get_or_create_compute(workspace=ws,\n",
    "                                       compute_target_name='mpi-test2',\n",
    "                                       vm_size='STANDARD_D2_V2',\n",
    "                                       max_nodes=3\n",
    "                                       )\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(cpu_cluster.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the compute target, let's see what the workspace's `compute_targets` property returns. You should now see one entry named 'cpucluster' of type `AmlCompute`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a simple script\n",
    "We have already created a simple \"hello world\" script. This is the script that we will submit through the estimator pattern. It prints a hello-world message, and if Azure ML SDK is installed, it will also logs an array of values ([Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Estimator object\n",
    "Estimator by default will attempt to use Docker-based execution. You can also enable Docker and let estimator pick the default CPU image supplied by Azure ML for execution. You can target an AmlCompute cluster (or any other supported compute target types). You can also customize the conda environment by adding conda and/or pip packages.\n",
    "\n",
    "> Note: The arguments to the entry script used in the Estimator object should be specified as *list* using\n",
    "    'estimator_entry_script_arguments' parameter when instantiating EstimatorStep. Estimator object's parameter\n",
    "    'script_params' accepts a dictionary. However 'estimator_entry_script_arguments' parameter expects arguments as\n",
    "    a list.\n",
    "\n",
    "> Estimator object initialization involves specifying a list of DataReference objects in its 'inputs' parameter.\n",
    "    In Pipelines, a step can take another step's output or DataReferences as input. So when creating an EstimatorStep,\n",
    "    the parameters 'inputs' and 'outputs' need to be set explicitly and that will override 'inputs' parameter\n",
    "    specified in the Estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./iris.csv\n",
      "Uploaded ./iris.csv, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_b5baefca9e994496ac78d936ba0c32a2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "\n",
    "def_blob_store.upload_files(['./iris.csv'], \n",
    "                                  target_path = 'iris', \n",
    "                                  overwrite = True, \n",
    "                                  show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"input_data\",\n",
    "    path_on_datastore=\"iris\")\n",
    "\n",
    "output = PipelineData(\"output\", datastore=def_blob_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import MpiConfiguration\n",
    "mpi_config = MpiConfiguration()\n",
    "mpi_config.process_count_per_node = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_est = {\n",
    "    'OG':{\n",
    "        'conda_packages':['scikit-learn'],\n",
    "        'entry_script':'dummy_train.py'\n",
    "    },\n",
    "    'MML_image':{\n",
    "        'node_count':1,\n",
    "        # distributed_training=mpi_config,\n",
    "        'use_gpu':True,\n",
    "        'conda_packages':['scikit-learn','pyspark', 'pandas', 'numpy'],\n",
    "        'pip_packages':['pip', 'findspark'],\n",
    "        'custom_docker_image':'microsoft/mmlspark:gpu-0.12',\n",
    "        'entry_script':'dummy_train.py'\n",
    "    },\n",
    "    'MML_use_spark':{\n",
    "        'node_count':1,\n",
    "        'use_gpu':True,\n",
    "        'conda_packages':['scikit-learn','pyspark', 'pandas', 'numpy'],\n",
    "        'pip_packages':['pip', 'findspark'],\n",
    "        'custom_docker_image':'microsoft/mmlspark:gpu-0.12',\n",
    "        'entry_script':'roll_iris.py'\n",
    "    },\n",
    "    'MML_MPI':{\n",
    "        'node_count':2,\n",
    "        'distributed_training':mpi_config,\n",
    "        'use_gpu':True,\n",
    "        'conda_packages':['scikit-learn','pyspark', 'pandas', 'numpy'],\n",
    "        'pip_packages':['pip', 'findspark'],\n",
    "        'custom_docker_image':'microsoft/mmlspark:gpu-0.12',\n",
    "        'entry_script':'roll_iris.py'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "est = Estimator(source_directory='.', \n",
    "                compute_target=cpu_cluster, \n",
    "               **config_est['MML_MPI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an EstimatorStep\n",
    "[EstimatorStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimator_step.estimatorstep?view=azure-ml-py) adds a step to run Estimator in a Pipeline.\n",
    "\n",
    "- **name:** Name of the step\n",
    "- **estimator:** Estimator object\n",
    "- **estimator_entry_script_arguments:** \n",
    "- **runconfig_pipeline_params:** Override runconfig properties at runtime using key-value pairs each with name of the runconfig property and PipelineParameter for that property\n",
    "- **inputs:** Inputs\n",
    "- **outputs:** Output is list of PipelineData\n",
    "- **compute_target:** Compute target to use \n",
    "- **allow_reuse:** Whether the step should reuse previous results when run with the same settings/inputs. If this is false, a new run will always be generated for this step during pipeline execution.\n",
    "- **version:** Optional version tag to denote a change in functionality for the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import EstimatorStep\n",
    "\n",
    "est_step = EstimatorStep(name=\"Estimator_Train\", \n",
    "                         estimator=est, \n",
    "                         runconfig_pipeline_params=None, \n",
    "                         estimator_entry_script_arguments=[\n",
    "                            '--input_dir', input_data,\n",
    "                            '--output_dir', output,\n",
    "                            '--script_dir', \".\",\n",
    "                         ],\n",
    "                         inputs=[input_data], \n",
    "                         outputs=[output], \n",
    "                         compute_target=cpu_cluster,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Submit the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "pipeline = Pipeline(workspace=ws, steps=[est_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Estimator_Train [5762d517][542d5e28-fe81-4a91-b7f1-1e88dffc9960], (This step will run and generate new outputs)\n",
      "Created data reference input_data for StepId [a28f10c5][4794d99c-87ab-41f4-85fa-d7ce08b888fa], (Consumers of this data will generate new runs.)\n",
      "Submitted pipeline run: b9c0ef19-58a2-4e34-9018-200ae07c6639\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = Experiment(ws, 'Estimator_sample').submit(pipeline,\n",
    "                                                        regenerate_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "accb1a503aa24c7bb1301cb69b703c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.tag(\"script\",\"roll_iris\")\n",
    "pipeline_run.tag(\"est\",\"shouldn't work\")\n",
    "pipeline_run.tag(\"compute\",\"holy roller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "kernelspec": {
   "display_name": "Python (aml39)",
   "language": "python",
   "name": "aml39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
